{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse as sps\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = 11\n",
    "A = np.random.normal(size = (d, 10))\n",
    "b = np.random.uniform(1, 0, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or use a real dataset in LibSVM format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A, b = load_svmlight_file(\"../data/ionosphere.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_iter(y, tx, batch_size, num_batches=1, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generate a minibatch iterator for a dataset.\n",
    "    Takes as input two iterables (here the output desired values 'y' and the input data 'tx')\n",
    "    Outputs an iterator which gives mini-batches of `batch_size` matching elements from `y` and `tx`.\n",
    "    Data can be randomly shuffled to avoid ordering in the original data messing with the randomness of the minibatches.\n",
    "    Example of use :\n",
    "    for minibatch_y, minibatch_tx in batch_iter(y, tx, 32):\n",
    "        <DO-SOMETHING>\n",
    "    \"\"\"\n",
    "    data_size = len(y)\n",
    "\n",
    "    if shuffle:\n",
    "        shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "        shuffled_y = y[shuffle_indices]\n",
    "        shuffled_tx = tx[shuffle_indices]\n",
    "    else:\n",
    "        shuffled_y = y\n",
    "        shuffled_tx = tx\n",
    "    for batch_num in range(num_batches):\n",
    "        start_index = batch_num * batch_size\n",
    "        end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "        if start_index != end_index:\n",
    "            yield shuffled_y[start_index:end_index], shuffled_tx[start_index:end_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic gradient descent for Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lasso_function(A, b, reg_coef, alpha):\n",
    "    return 0.5 * np.linalg.norm(A.dot(alpha) - b) ** 2 + reg_coef * np.sum(np.abs(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_stoch_gradient_lasso(A, b, reg_coef, alpha):\n",
    "    \"\"\"Compute a stochastic gradient from just few examples n and their corresponding y_n labels.\"\"\"\n",
    "    err = b - A.dot(alpha)\n",
    "    gradient = - A.T.dot(err) + reg_coef * np.sign(alpha) * A.shape[0]\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent_lasso(A, b, reg_coef, gamma, batch_size=1, max_iter=1000, trace=False):\n",
    "    history = defaultdict(list) if trace else None\n",
    "    \n",
    "    num_data_points, num_features = np.shape(A)\n",
    "    alpha_t = np.zeros(num_features)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for current_iter in range(0, max_iter):\n",
    "        if trace:\n",
    "            history['time'].append(time.time() - start_time)\n",
    "            history['objective_function'].append(lasso_function(A, b, reg_coef, alpha_t))\n",
    "        ...\n",
    "        \n",
    "    return alpha_t, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t, history = stochastic_gradient_descent_lasso(A, b, 0.1, 0.001, max_iter=5000, trace=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.semilogx(history['objective_function']) # log scale\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"objective value\")\n",
    "plt.title(\"objective value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Coordinate Descent for Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def soft_threshold(internal, reg_coef, current_feature_norm):\n",
    "    if internal > reg_coef:\n",
    "        return (internal - reg_coef) / (current_feature_norm ** 2)\n",
    "    elif internal < - reg_coef:\n",
    "        return (internal + reg_coef) / (current_feature_norm ** 2)\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coordinate_descent_lasso(A, b, reg_coef, max_iter=1000, trace=False, is_check=False,\n",
    "                             check_epsilon=1e-1):\n",
    "    history = defaultdict(list) if trace else None\n",
    "\n",
    "    num_features = np.shape(A)[1]\n",
    "    alpha_t = np.zeros(num_features)\n",
    "    residual = np.copy(b)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for current_iter in range(0, max_iter):\n",
    "        if trace:\n",
    "            history['time'].append(time.time() - start_time)\n",
    "            history['objective_function'].append(lasso_function(A, b, reg_coef, alpha_t))\n",
    "        i = np.random.randint(0, num_features)\n",
    "        if sps.issparse(A):\n",
    "            current_feature = np.array(A[:, i].todense())\n",
    "        else:\n",
    "            current_feature = np.array(A[:, i])\n",
    "\n",
    "        current_feature_norm = np.linalg.norm(current_feature)\n",
    "        if current_feature_norm == 0:\n",
    "            alpha_t[i] = 0\n",
    "            continue\n",
    "        \n",
    "        ...\n",
    "\n",
    "        new_value = soft_threshold( ... , reg_coef, current_feature_norm)\n",
    "        residual += (current_feature * (alpha_t[i] - new_value)).reshape(residual.shape)\n",
    "        alpha_t[i] = np.copy(new_value)\n",
    "\n",
    "        if is_check:  # implement an optional check if a slightly smaller or larger step on \n",
    "                      # the current coordinate would indeed make the function value worse\n",
    "            \n",
    "    return alpha_t, residual, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally run the optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t, residual, history = coordinate_descent_lasso(A, b, 0.1, max_iter=1000, trace=True,\n",
    "                                                  is_check=True, check_epsilon=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.semilogx(history['objective_function'])\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"objective value\")\n",
    "plt.title(\"objective value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
